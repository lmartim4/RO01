{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 2 Part 2 - DDP for Two Heated Tanks\n",
    "\n",
    "This notebook implements Differential Dynamic Programming (DDP) for the two heated tanks system.\n",
    "\n",
    "**Key differences from Part 1:**\n",
    "- Part 1 used binary control (ON/OFF) with P-controller and LQR\n",
    "- Part 2 uses continuous control with DDP for optimal trajectory generation\n",
    "\n",
    "**Tasks:**\n",
    "- Implement DDP algorithm for the two heated tanks\n",
    "- Compare with LQR results from Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import bisect as bi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions for Grid Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edInt(a, s, b):\n",
    "    \"\"\"Create evenly discretized interval from a to b with step s\"\"\"\n",
    "    return np.linspace(a, b, int(np.floor((b-a)/s)) + 1)\n",
    "\n",
    "def idx(aList, val):\n",
    "    \"\"\"Find nearest index in sorted list for given value\"\"\"\n",
    "    i = bi.bisect(aList, val)  # right insertion point\n",
    "    if i <= 0:  # val is before first element\n",
    "        return 0\n",
    "    elif i >= len(aList):  # val is after last element\n",
    "        return len(aList) - 1\n",
    "    elif val - aList[i-1] < aList[i] - val:  # closer to left\n",
    "        return i - 1\n",
    "    else:  # closer to right\n",
    "        return i\n",
    "\n",
    "def lookup(aList, vals):\n",
    "    \"\"\"Find nearest indices for values (nearest-neighbor interpolation)\"\"\"\n",
    "    if isinstance(vals, (int, float, np.floating)):\n",
    "        vals = [vals]\n",
    "    return np.array([idx(aList, v) for v in vals], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Parameters (Mode 1: ON1 ∧ OFF2)\n",
    "\n",
    "Same parameters as TP2 Part 1:\n",
    "\n",
    "$$\\dot{T}_1 = -a_1 T_1 + b_1 T_2 + h_1 u_1$$\n",
    "$$\\dot{T}_2 = b_2 T_1 - a_2 T_2 + h_2 u_2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System parameters (from TP2 Part 1)\n",
    "a1 = 0.01   # Heat loss coefficient tank 1\n",
    "a2 = 0.01   # Heat loss coefficient tank 2\n",
    "b1 = 0.005  # Coupling coefficient 2→1\n",
    "b2 = 0.005  # Coupling coefficient 1→2\n",
    "h1 = 2.0    # Heater gain tank 1\n",
    "h2 = 2.0    # Heater gain tank 2\n",
    "\n",
    "print(f\"System parameters:\")\n",
    "print(f\"a1={a1}, a2={a2}, b1={b1}, b2={b2}, h1={h1}, h2={h2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDP Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time horizon\n",
    "t0 = 0\n",
    "dt = 0.1     # Time step (smaller for better accuracy)\n",
    "tf = 100     # Final time\n",
    "T = edInt(t0, dt, tf)\n",
    "N = T.size\n",
    "\n",
    "# State space discretization (temperature ranges)\n",
    "dT1 = 1.0    # Temperature step for tank 1 (finer grid)\n",
    "dT2 = 1.0    # Temperature step for tank 2\n",
    "T1_min, T1_max = 0, 60    # Tank 1 temperature range °C\n",
    "T2_min, T2_max = 0, 60    # Tank 2 temperature range °C\n",
    "\n",
    "# Control space discretization\n",
    "du1 = 0.25   # Control step for heater 1\n",
    "du2 = 0.25   # Control step for heater 2\n",
    "u1_min, u1_max = 0, 3     # Control range for heater 1\n",
    "u2_min, u2_max = 0, 3     # Control range for heater 2\n",
    "\n",
    "# Create admissible sets\n",
    "T1_grid = edInt(T1_min, dT1, T1_max)\n",
    "T2_grid = edInt(T2_min, dT2, T2_max)\n",
    "U1 = edInt(u1_min, du1, u1_max)\n",
    "U2 = edInt(u2_min, du2, u2_max)\n",
    "\n",
    "# Create state space meshgrid\n",
    "T1_mesh, T2_mesh = np.meshgrid(T1_grid, T2_grid)\n",
    "\n",
    "# Initial and reference states (same as TP2 Part 1)\n",
    "x0 = np.array([0.0, 50.0])   # Initial temperatures [T1, T2]\n",
    "x_ref = np.array([25.0, 30.0])  # Reference temperatures [T1, T2]\n",
    "\n",
    "# Penalty for inadmissible states\n",
    "infStValInc = 1e6\n",
    "nullCtr = 0.0\n",
    "\n",
    "print(f\"Time horizon: {t0} to {tf} s with dt={dt} s ({N} steps)\")\n",
    "print(f\"State space: T1 ∈ [{T1_min}, {T1_max}]°C (step {dT1}), T2 ∈ [{T2_min}, {T2_max}]°C (step {dT2})\")\n",
    "print(f\"State grid sizes: {T1_grid.size} x {T2_grid.size} = {T1_grid.size * T2_grid.size} states\")\n",
    "print(f\"Control space: u1 ∈ [{u1_min}, {u1_max}] (step {du1}), u2 ∈ [{u2_min}, {u2_max}] (step {du2})\")\n",
    "print(f\"Control grid sizes: {U1.size} x {U2.size} = {U1.size * U2.size} control combinations\")\n",
    "print(f\"Initial state: T1={x0[0]}°C, T2={x0[1]}°C\")\n",
    "print(f\"Reference state: T1={x_ref[0]}°C, T2={x_ref[1]}°C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function\n",
    "\n",
    "$$L(x, u) = Q_1(T_1 - T_1^{ref})^2 + Q_2(T_2 - T_2^{ref})^2 + R_1 u_1^2 + R_2 u_2^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost matrices (similar to LQR weights from Part 1)\n",
    "Q1 = 10.0    # State cost weight for tank 1\n",
    "Q2 = 10.0    # State cost weight for tank 2\n",
    "R1 = 1.0     # Control cost weight for heater 1\n",
    "R2 = 1.0     # Control cost weight for heater 2\n",
    "\n",
    "print(f\"Cost weights: Q1={Q1}, Q2={Q2}, R1={R1}, R2={R2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Value Function and Optimal Control Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize arrays\n",
    "# V[i, j, k] = optimal cost-to-go from state (T1_grid[j], T2_grid[i]) at time k\n",
    "# u1_opt[i, j, k] = optimal control u1 at state (T1_grid[j], T2_grid[i]) at time k\n",
    "# u2_opt[i, j, k] = optimal control u2 at state (T1_grid[j], T2_grid[i]) at time k\n",
    "V = np.zeros((T2_grid.size, T1_grid.size, N))\n",
    "u1_opt = np.zeros_like(V)\n",
    "u2_opt = np.zeros_like(V)\n",
    "\n",
    "# Terminal cost (at time N-1)\n",
    "V[:, :, N-1] = Q1 * (T1_mesh - x_ref[0])**2 + Q2 * (T2_mesh - x_ref[1])**2\n",
    "\n",
    "print(f\"Initialized V with shape: {V.shape}\")\n",
    "print(f\"Terminal cost V[:,:,{N-1}] set based on reference state\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDP Backward Pass (Value Iteration)\n",
    "\n",
    "Bellman equation:\n",
    "$$V(x, k) = \\min_{u_1, u_2} \\left[ L(x, u) + V(f(x, u), k+1) \\right]$$\n",
    "\n",
    "where $f(x,u)$ is the next state given by the system dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting DDP backward pass...\")\n",
    "print(f\"Processing {N-1} time steps x {T2_grid.size} x {T1_grid.size} states x {U1.size} x {U2.size} controls\")\n",
    "print(f\"Total iterations: {(N-1) * T2_grid.size * T1_grid.size}\")\n",
    "print(\"This may take a minute...\\n\")\n",
    "\n",
    "depth = 0  # Start from beginning of horizon\n",
    "inadmissible_count = 0\n",
    "\n",
    "for k in range(N-2, depth-1, -1):  # Go backwards from N-2 to 0\n",
    "    if k % 100 == 0:\n",
    "        print(f\"Processing time step {k}/{N-2}...\")\n",
    "    \n",
    "    for i in range(T2_grid.size):\n",
    "        for j in range(T1_grid.size):\n",
    "            # Current state\n",
    "            T1_curr = T1_grid[j]\n",
    "            T2_curr = T2_grid[i]\n",
    "            \n",
    "            # Initialize minimum cost\n",
    "            min_cost = float('inf')\n",
    "            best_u1 = nullCtr\n",
    "            best_u2 = nullCtr\n",
    "            \n",
    "            # Try all control combinations\n",
    "            for u1_val in U1:\n",
    "                for u2_val in U2:\n",
    "                    # Instant cost\n",
    "                    L = Q1 * (T1_curr - x_ref[0])**2 + Q2 * (T2_curr - x_ref[1])**2 + \\\n",
    "                        R1 * u1_val**2 + R2 * u2_val**2\n",
    "                    \n",
    "                    # Predict next state using mode 1 dynamics\n",
    "                    T1_next = T1_curr + (-a1 * T1_curr + b1 * T2_curr + h1 * u1_val) * dt\n",
    "                    T2_next = T2_curr + (b2 * T1_curr - a2 * T2_curr + h2 * u2_val) * dt\n",
    "                    \n",
    "                    # Check if next state is admissible\n",
    "                    if (T1_next >= T1_min and T1_next <= T1_max and \n",
    "                        T2_next >= T2_min and T2_next <= T2_max):\n",
    "                        \n",
    "                        # Find nearest grid indices (nearest-neighbor interpolation)\n",
    "                        j_next = lookup(T1_grid, T1_next)[0]\n",
    "                        i_next = lookup(T2_grid, T2_next)[0]\n",
    "                        \n",
    "                        # Bellman equation: total cost = instant cost + future cost\n",
    "                        total_cost = L + V[i_next, j_next, k+1]\n",
    "                        \n",
    "                        # Update if this is better\n",
    "                        if total_cost < min_cost:\n",
    "                            min_cost = total_cost\n",
    "                            best_u1 = u1_val\n",
    "                            best_u2 = u2_val\n",
    "            \n",
    "            # Store optimal cost and control\n",
    "            if min_cost == float('inf'):\n",
    "                # No admissible control found - penalize\n",
    "                V[i, j, k] = V[i, j, k+1] + infStValInc\n",
    "                inadmissible_count += 1\n",
    "            else:\n",
    "                V[i, j, k] = min_cost\n",
    "            \n",
    "            u1_opt[i, j, k] = best_u1\n",
    "            u2_opt[i, j, k] = best_u2\n",
    "\n",
    "print(f\"\\nDDP backward pass complete!\")\n",
    "print(f\"Inadmissible state-time points: {inadmissible_count} / {(N-1) * T2_grid.size * T1_grid.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Simulation Using Optimal Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate from initial state\n",
    "x = np.zeros((N, 2))\n",
    "x[0, :] = x0\n",
    "u1_sim = np.zeros(N)\n",
    "u2_sim = np.zeros(N)\n",
    "\n",
    "print(f\"Starting forward simulation from x0 = {x0}\")\n",
    "\n",
    "for k in range(N-1):\n",
    "    # Check if current state is admissible\n",
    "    if not (x[k, 0] >= T1_min and x[k, 0] <= T1_max and\n",
    "            x[k, 1] >= T2_min and x[k, 1] <= T2_max):\n",
    "        print(f\"Warning: Stopped at k={k}/{N}: state [{x[k,0]:.2f}, {x[k,1]:.2f}] out of bounds\")\n",
    "        x = x[:k+1, :]\n",
    "        u1_sim = u1_sim[:k+1]\n",
    "        u2_sim = u2_sim[:k+1]\n",
    "        T = T[:k+1]\n",
    "        break\n",
    "    \n",
    "    # Find nearest grid indices\n",
    "    j_T1 = lookup(T1_grid, x[k, 0])[0]\n",
    "    i_T2 = lookup(T2_grid, x[k, 1])[0]\n",
    "    \n",
    "    # Get optimal control\n",
    "    u1_sim[k] = u1_opt[i_T2, j_T1, k]\n",
    "    u2_sim[k] = u2_opt[i_T2, j_T1, k]\n",
    "    \n",
    "    # Propagate dynamics\n",
    "    x[k+1, 0] = x[k, 0] + (-a1 * x[k, 0] + b1 * x[k, 1] + h1 * u1_sim[k]) * dt\n",
    "    x[k+1, 1] = x[k, 1] + (b2 * x[k, 0] - a2 * x[k, 1] + h2 * u2_sim[k]) * dt\n",
    "\n",
    "print(f\"Simulation complete!\")\n",
    "print(f\"Final state: T1={x[-1,0]:.2f}°C, T2={x[-1,1]:.2f}°C\")\n",
    "print(f\"Reference: T1={x_ref[0]}°C, T2={x_ref[1]}°C\")\n",
    "print(f\"Final error: T1={x[-1,0]-x_ref[0]:.2f}°C, T2={x[-1,1]-x_ref[1]:.2f}°C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "\n",
    "# State trajectories\n",
    "ax1 = plt.subplot(3, 3, 1)\n",
    "ax1.plot(T[:len(x)], x[:, 0], 'b-', linewidth=2, label='Tank 1 (DDP)')\n",
    "ax1.axhline(y=x_ref[0], color='red', linestyle='--', label=f'Reference ({x_ref[0]}°C)')\n",
    "ax1.set_xlabel('Time [s]')\n",
    "ax1.set_ylabel('Temperature [°C]')\n",
    "ax1.set_title('Tank 1 Temperature Trajectory')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2 = plt.subplot(3, 3, 2)\n",
    "ax2.plot(T[:len(x)], x[:, 1], 'orange', linewidth=2, label='Tank 2 (DDP)')\n",
    "ax2.axhline(y=x_ref[1], color='red', linestyle='--', label=f'Reference ({x_ref[1]}°C)')\n",
    "ax2.set_xlabel('Time [s]')\n",
    "ax2.set_ylabel('Temperature [°C]')\n",
    "ax2.set_title('Tank 2 Temperature Trajectory')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Control signals\n",
    "ax3 = plt.subplot(3, 3, 4)\n",
    "ax3.plot(T[:len(u1_sim)], u1_sim, 'g-', linewidth=2, label='u1 (Heater 1)')\n",
    "ax3.set_xlabel('Time [s]')\n",
    "ax3.set_ylabel('Control Signal')\n",
    "ax3.set_title('Optimal Control - Heater 1')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "ax4 = plt.subplot(3, 3, 5)\n",
    "ax4.plot(T[:len(u2_sim)], u2_sim, 'm-', linewidth=2, label='u2 (Heater 2)')\n",
    "ax4.set_xlabel('Time [s]')\n",
    "ax4.set_ylabel('Control Signal')\n",
    "ax4.set_title('Optimal Control - Heater 2')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# State space trajectory\n",
    "ax5 = plt.subplot(3, 3, 3)\n",
    "ax5.plot(x[:, 0], x[:, 1], 'b-', linewidth=2, alpha=0.7)\n",
    "ax5.plot(x[0, 0], x[0, 1], 'go', markersize=10, label='Initial')\n",
    "ax5.plot(x[-1, 0], x[-1, 1], 'ro', markersize=10, label='Final')\n",
    "ax5.plot(x_ref[0], x_ref[1], 'r*', markersize=15, label='Reference')\n",
    "ax5.set_xlabel('T1 [°C]')\n",
    "ax5.set_ylabel('T2 [°C]')\n",
    "ax5.set_title('State Space Trajectory')\n",
    "ax5.legend()\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# Value function at t=0\n",
    "ax6 = plt.subplot(3, 3, 6, projection='3d')\n",
    "ax6.plot_surface(T1_mesh, T2_mesh, V[:, :, 0], cmap='viridis', alpha=0.8)\n",
    "# Mark initial state value\n",
    "j_x0 = lookup(T1_grid, x0[0])[0]\n",
    "i_x0 = lookup(T2_grid, x0[1])[0]\n",
    "V_x0 = V[i_x0, j_x0, 0]\n",
    "ax6.plot([x0[0]], [x0[1]], [V_x0], 'r*', markersize=15)\n",
    "ax6.set_xlabel('T1 [°C]')\n",
    "ax6.set_ylabel('T2 [°C]')\n",
    "ax6.set_zlabel('V(x, t=0)')\n",
    "ax6.set_title(f'Value Function at t=0\\nV(x0)={V_x0:.2f}')\n",
    "\n",
    "# Value function at terminal time\n",
    "ax7 = plt.subplot(3, 3, 9, projection='3d')\n",
    "ax7.plot_surface(T1_mesh, T2_mesh, V[:, :, N-1], cmap='plasma', alpha=0.8)\n",
    "ax7.set_xlabel('T1 [°C]')\n",
    "ax7.set_ylabel('T2 [°C]')\n",
    "ax7.set_zlabel('V(x, t=tf)')\n",
    "ax7.set_title('Terminal Cost (t=tf)')\n",
    "\n",
    "# Optimal control policy u1 at t=0\n",
    "ax8 = plt.subplot(3, 3, 7, projection='3d')\n",
    "ax8.plot_surface(T1_mesh, T2_mesh, u1_opt[:, :, 0], cmap='coolwarm', alpha=0.8)\n",
    "ax8.set_xlabel('T1 [°C]')\n",
    "ax8.set_ylabel('T2 [°C]')\n",
    "ax8.set_zlabel('u1*')\n",
    "ax8.set_title('Optimal Control u1 at t=0')\n",
    "\n",
    "# Optimal control policy u2 at t=0\n",
    "ax9 = plt.subplot(3, 3, 8, projection='3d')\n",
    "ax9.plot_surface(T1_mesh, T2_mesh, u2_opt[:, :, 0], cmap='coolwarm', alpha=0.8)\n",
    "ax9.set_xlabel('T1 [°C]')\n",
    "ax9.set_ylabel('T2 [°C]')\n",
    "ax9.set_zlabel('u2*')\n",
    "ax9.set_title('Optimal Control u2 at t=0')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance metrics\n",
    "ss_error_T1 = x[-1, 0] - x_ref[0]\n",
    "ss_error_T2 = x[-1, 1] - x_ref[1]\n",
    "\n",
    "# Calculate total cost\n",
    "total_cost = 0\n",
    "for k in range(len(x)-1):\n",
    "    L_k = Q1 * (x[k, 0] - x_ref[0])**2 + Q2 * (x[k, 1] - x_ref[1])**2 + \\\n",
    "          R1 * u1_sim[k]**2 + R2 * u2_sim[k]**2\n",
    "    total_cost += L_k * dt\n",
    "\n",
    "# Terminal cost\n",
    "L_N = Q1 * (x[-1, 0] - x_ref[0])**2 + Q2 * (x[-1, 1] - x_ref[1])**2\n",
    "total_cost += L_N\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PERFORMANCE METRICS - DDP\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Steady-state error Tank 1: {ss_error_T1:.4f} °C\")\n",
    "print(f\"Steady-state error Tank 2: {ss_error_T2:.4f} °C\")\n",
    "print(f\"Total accumulated cost: {total_cost:.2f}\")\n",
    "print(f\"Optimal value at x0: {V_x0:.2f}\")\n",
    "print(f\"\\nAverage control effort:\")\n",
    "print(f\"  u1: {np.mean(u1_sim):.4f} (max: {np.max(u1_sim):.4f})\")\n",
    "print(f\"  u2: {np.mean(u2_sim):.4f} (max: {np.max(u2_sim):.4f})\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with LQR (from Part 1)\n",
    "\n",
    "**Key Differences:**\n",
    "\n",
    "1. **DDP (this notebook):**\n",
    "   - Finite-horizon optimal control\n",
    "   - Time-varying optimal policy\n",
    "   - Can handle constraints naturally\n",
    "   - Computationally expensive (backward pass)\n",
    "\n",
    "2. **LQR (Part 1):**\n",
    "   - Infinite-horizon optimal control\n",
    "   - Time-invariant feedback gain\n",
    "   - Analytical solution\n",
    "   - Computationally efficient\n",
    "\n",
    "**When to use DDP:**\n",
    "- Finite time horizon problems\n",
    "- Time-varying systems or costs\n",
    "- State/control constraints\n",
    "- Trajectory optimization\n",
    "\n",
    "**When to use LQR:**\n",
    "- Regulation around equilibrium\n",
    "- Real-time control (fast)\n",
    "- Linear systems with quadratic cost\n",
    "- No hard constraints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
